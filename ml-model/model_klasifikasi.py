# -*- coding: utf-8 -*-
"""model-klasifikasi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1opgQeG_n-vR3Q7_i6eXdSonAi0U4lv0v
"""

! pip install kaggle

! mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

# Mendownload dan menyiapkan dataset 
! kaggle datasets download iabhishekofficial/mobile-price-classification

# Mengekstrak zip file
import zipfile

local_zip = '/content/mobile-price-classification.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content')
zip_ref.close()

#from google.colab import drive
#drive.mount('/content/drive')

# Mengubah dataset menjadi dataframe
import pandas as pd

df = pd.read_csv('/content/train.csv')
df.head()

df.info()

df.describe()

df.isnull().sum()

# Memeriksa rasionalitas beberapa variabel
px_h = (df.px_height==0).sum()
px_w = (df.px_width==0).sum()
sc_h = (df.sc_h==0).sum()
sc_w = (df.sc_w==0).sum()

print(px_h)
print(px_w)
print(sc_h)
print(sc_w)

# Menghapus nilai yang tidak rasional pada variabel
df = df.loc[(df[['px_height','sc_w']]!=0).all(axis=1)]
df.shape

# Proses drop outliers
Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR=Q3-Q1
df=df[~((df<(Q1-1.5*IQR))|(df>(Q3+1.5*IQR))).any(axis=1)]
 
# Cek ukuran dataset setelah outliers didrop
df.shape

# Commented out IPython magic to ensure Python compatibility.
# Melakukan proses analisis data dengan teknik Univariate EDA
import matplotlib.pyplot as plt
# %matplotlib inline

df.hist(bins=50, figsize=(20,15))
plt.show()

df_new = pd.DataFrame()

df_new['Weight(g)'] = df['mobile_wt'].copy()
df_new['Width(px)'] = df['px_width'].copy()
df_new['Height(px)'] = df['px_height'].copy()
df_new['ROM(MB)'] = df['int_memory'].copy()
df_new['RAM(MB)'] = df['ram'].copy()
df_new['Battery Capacity(mAh)'] = df['battery_power'].copy()
df_new['Price'] = df['price_range'].copy()

df_new

"""##################################################################################################

# ADD DATASET
"""

df_add = pd.read_csv('/content/smartphone_specs.csv')
df_add

df_add = df_add.rename(columns={'Price(USD)': 'Price'})

df_add.isnull().sum()

df_add = df_add.dropna()

df_add.isnull().sum()

df_add.describe()

df_add = df_add.loc[df_add['Weight(g)']<=200]

df_add

df_add.loc[df_add['Price']<100, 'Price'] = 0
df_add.loc[(df_add['Price']>=100) & (df_add['Price']<200), 'Price'] = 1
df_add.loc[(df_add['Price']>=200) & (df_add['Price']<400), 'Price'] = 2
df_add.loc[df_add['Price']>=400, 'Price'] = 3

df_add.describe()

df_add

df_add.Brand.unique()

(df_add.loc[(df_add['Brand']=='samsung') & (df_add['Price']==1)]).describe()

samsung = df_add.loc[df_add['Brand']=='samsung']
samsung = samsung.drop(columns=['Brand','Model Name','Model Image'])

oppo = df_add.loc[df_add['Brand']=='oppo']
oppo = oppo.drop(columns=['Brand','Model Name','Model Image'])

vivo = df_add.loc[df_add['Brand']=='vivo']
vivo = vivo.drop(columns=['Brand','Model Name','Model Image'])

xiaomi = df_add.loc[df_add['Brand']=='xiaomi']
xiaomi = xiaomi.drop(columns=['Brand','Model Name','Model Image'])

realme = df_add.loc[df_add['Brand']=='realme']
realme = realme.drop(columns=['Brand','Model Name','Model Image'])

#apple = df_add.loc[df_add['Brand']=='apple']
#apple = apple.drop(columns=['Brand','Model Name','Model Image'])

print(len(df_new))
print(len(samsung))
print(len(oppo))
print(len(vivo))
print(len(xiaomi))
print(len(realme))
#print(len(apple))

"""####################################################################################"""

df_final = pd.concat([df_new, samsung, vivo, oppo, xiaomi, realme], ignore_index=True, sort=False)
#df_final = pd.concat([df_new, samsung, vivo, oppo, xiaomi, realme, apple], ignore_index=True, sort=False)

df_final

(df_final.loc[df_final['Price']==0]).describe()

(df_final.loc[df_final['Price']==1]).describe()

(df_final.loc[df_final['Price']==2]).describe()

(df_final.loc[df_final['Price']==3]).describe()

df_final.isnull().sum()

df_final.info()

df_final.describe()

(df_final['Height(px)']==1).sum()

# Menghapus nilai yang tidak rasional pada variabel
df_final = df_final.loc[(df_final['Height(px)']!=1)]
df_final.shape

df_final.describe()

df_final

import seaborn as sns
sns.boxplot(x=df_final['Weight(g)'])

sns.boxplot(x=df_final['Width(px)'])

sns.boxplot(x=df_final['Height(px)'])

sns.boxplot(x=df_final['ROM(MB)'])

sns.boxplot(x=df_final['RAM(MB)'])

sns.boxplot(x=df_final['Battery Capacity(mAh)'])

# Proses drop outliers
Q1 = df_final.quantile(0.25)
Q3 = df_final.quantile(0.75)
IQR=Q3-Q1
df_final=df_final[~((df_final<(Q1-1.5*IQR))|(df_final>(Q3+1.5*IQR))).any(axis=1)]
 
# Cek ukuran dataset setelah outliers didrop
df_final.shape

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

df_final.hist(bins=50, figsize=(20,15))
plt.show()

list(df_final.columns.values[:6])

"""########################################################################"""

plt.figure(figsize=(10, 8))
correlation_matrix = df_final.corr().round(2)

sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""########################################################################"""

from sklearn.model_selection import train_test_split

b = df_final['Price'] 


li = list(df_final.columns.values[:6])
a = df_final[li]

# Split dataset menjadi train dan test
a_train, a_test, b_train, b_test = train_test_split(a, b, test_size=0.2, random_state=123)

from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics

clf=RandomForestClassifier(n_estimators = 100, oob_score = True,n_jobs = 1,random_state =1)

clf.fit(a_train,b_train)

y_pred=clf.predict(a_test)


print("Accuracy:",metrics.accuracy_score(b_test, y_pred))

var_imp = pd.Series(clf.feature_importances_,index=list(df_final.columns.values[:6])).sort_values(ascending=False)
var_imp

(df_final.loc[df_final['Price']==0]).describe()

import numpy as np
print(clf.predict(np.array([[int(i) for i in input().split()]])))

# Membuat bar plot
sns.barplot(x=var_imp, y=var_imp.index)
plt.xlabel('Skor variabel penting')
plt.ylabel('Variabel')
plt.title('Visualisasi variabel penting')
plt.legend()
plt.show()

from sklearn.model_selection import train_test_split

y = df_final['Price'] 

# Ambil fitur penting
li = list(df_final.columns.values[:6])
X = df_final[li]
# Split dataset menjadi train dan test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)

print(X_test.shape)
print(X_train.shape)

# Model KNN
from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics

knn = KNeighborsClassifier(n_neighbors=9)

knn.fit(X_train, y_train)

y_pred = knn.predict(X_test)

a_KNN = metrics.accuracy_score(y_test, y_pred)
print("Accuracy:",a_KNN)

from sklearn.svm import SVC

svm = SVC(kernel='linear',C=0.025,random_state=123)
svm.fit(X_train, y_train)

y_pred = svm.predict(X_test)

a_svmSVC = metrics.accuracy_score(y_test, y_pred)
print("Accuracy:",a_svmSVC)

from sklearn.preprocessing import StandardScaler
numerical_features = ['Weight(g)', 'Width(px)', 'Height(px)', 'ROM(MB)', 'RAM(MB)', 'Battery Capacity(mAh)']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features]

X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])
X_test.loc[:, numerical_features]

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression(max_iter=10000, random_state=123)
lr.fit(X_train, y_train)

y_pred = lr.predict(X_test)

a_lr = metrics.accuracy_score(y_test, y_pred)
print("Accuracy:",a_lr)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import LinearSVC


#K-Nearest Neigbors classifier
KNN_model = KNeighborsClassifier(n_neighbors=5)
KNN_model.fit(X_train,y_train)
KNNPrediction = KNN_model.predict(X_test)

#Decision Tree Classifier
decissionTree = DecisionTreeClassifier(criterion='entropy',random_state=0)
decissionTree.fit(X_train,y_train)
TreePrediction = decissionTree.predict(X_test)

#Support Vector Machine Classifier
SVM = LinearSVC(random_state=0, max_iter=10000)
SVM.fit(X_train, y_train)
SVMPrediction = SVM.predict(X_test)

from sklearn.metrics import accuracy_score
#Kode untuk melihat akurasi
print("Accuracy Score of KNN:",accuracy_score(y_test,KNNPrediction))
print("Accuracy Score of Decision Tree:",accuracy_score(y_test,TreePrediction))
print("Accuracy Score of SVM:",accuracy_score(y_test,SVMPrediction))

from sklearn.metrics import classification_report
print(classification_report(b_test, y_pred))